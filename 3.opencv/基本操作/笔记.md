# 前置知识

1.图像的两种分类以及图像在计算机中的存储

​	图像分为两种：**彩色图**和**灰度图**（黑白图），彩色图就是五颜六色的图，灰度图是黑白的，本质上是两种图像在计算机中的存储不一样。

​	【计算机眼中的图像】计算机中的图像其实是一个**二维矩阵**，矩阵的**每一个位置对应了**图片的每一个最小单位 - 像素，在计算机存储图片的时候，**一个像素**其实是**一个/一组值**。对于**灰度图**而言，一个像素点对应了一个**uint8**类型的整数，范围是**0-255**，正好用一个八位的无符号整数存储。如下图矩阵所示：

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250901194530713.png" width="300px">

​	而对于**彩色图**来说，我们知道，**所有的颜色都可以用红绿蓝三种颜色按照不同的比例/权重叠加之后显式出来**，所以我们可以用一个**长度为3的元组唯一标识**一个像素点，**(B,G,R)**，每一个维度的范围都是**0-255**，这里的**每一个维度**叫做**通道（channel）**。**彩色图是三通道**的，而**灰度图是单通道**的。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250901195446658.png" width="300px">

​	**通道的值**（0-255）可以理解为**亮度**，**数字的值越小，代表亮度低**，亮度**最低就是纯黑色**-0，**亮度最高就是白色255**. 这对于B，G，R三个通道而言同样适用，以**R通道为例**，0代表黑色，255代表白色，**中间是不同程度的红色**。对于单通道的**灰度图而言**，中间是**不同程度的灰色**（介于黑色和白色之间的颜色）。

2.视频在计算机中的存储

​	视频就是一帧一帧按照时间序列摆放起来，依次播放得到的**图像序列**，所以视频是由一帧一帧图像构成的，**一帧就是一张瞬时的图片**，所以对视频的处理，**本质上可以归结于对图像的处理上**，只要计算性能足够，视频就可以处理。

# 环境配置

1.安装Anaconda

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250901202801914.png" width="300px">

2.用**管理员权限**安装到**自己的开发路径**下面。需要先**创建一个空的文件夹（比如我的D:/develop/Anaconda3）**。然后选择这个路径即可安装。

// 安装完Anaconda，里面自带notebook，无需额外自己pip install。

// **这一套安装完成之后，就可以在任何的位置输入cmd的jupyter notebook启动了，然后就可以在任何位置打开ipynb文件并使用cv2的库了，Anaconda3集成了这些库。**

=> 扩展，以后**<u>自己的项目用Anaconda3作为环境</u>**（包含解释器，一些依赖-如cv2等，不需要自己pip install了）。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902183043475.png" width="500px">

# 基本操作

## 图片的读、存、可视化和常见属性

1.读取图片 imread方法

①读取彩色图片（默认）为numpy中的ndarray对象 - **imread方法，传入图片路径。**

```python
import numpy
import matplotlib.pyplot as plt
import cv2
%matplotlib inline

img = cv2.imread('dog.png')
print(img)
```

结果是

```python
[[[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]

 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
 [[255 255 255]
  [255 255 255]
  [255 255 255]
  ...
  [255 255 255]
  [255 255 255]
  [255 255 255]]]
```

​	你会发现一组值是一个三元组，对应一个像素点，外层这对应图片的一行，若干行共同构成一张彩色图。

// 你也可以直接输入一个变量，然后直接输出这个变量。如下图,不需要print这个变量

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250901212307126.png" width="400px">

②读取灰度图，只需要手动添加第二个参数

​	读取为灰度图，imread方法默认读的是彩色图（默认第二个参数是` cv2.IMREAD_COLOR`），传入第二个参数为`cv2.IMREAD_GRAYSCALE` 即可读取得到一个单通道的灰度图img对象。

`img_gray = cv2.imread('dog.png', cv2.IMREAD_GRAYSCALE)`

输出img_gray，可以看到是单通道的图

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902183921968.png" width="400px">

显示图片：

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902184044567.png" width="200px">

查看灰度图的shape，发现单通道channel = 1省略了，只有h和w。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902184400143.png" width="200px">

2.保存图片 imwrite方法

​	`imwrite方法`，把img对象存储到指定的路径。记得**在写输出路径的时候，不要忘记写扩展名**。

```python
# 把灰度图保存到指定路径
cv2.imwrite('gray_dog.png', img_gray)
```

3.可视化图片 imshow方法

​	渲染图像出来为一个窗口 - `imshow方法，第一个参数是窗口的title，第二个参数是图像对象`

```python
cv2.imshow('dog-show', img)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

​	推荐搭配后面两个方法一起封装为一个show_img方法，传入一个path，waitKey传入0的意思是等待键盘中的任意键出发一个行为，后面调用destroyAllWindows为设置关闭窗口行为；如果传入的不是0，而是一个具体的数，则窗口会在x ms后自动触发行为，比如传入1000，意思是1s后自动关闭。推荐传入0，所以可以封装为一个方法打印来用。

demo:

```python
# 打印image图像，测试观察结果，按任意键关闭。
def show_img(w_name, image):
    cv2.imshow(w_name, image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
show_img('small_dog', img)
```

4.图片转换 cvtColor方法

​	cv2的cvtColor方法可以实现彩色图和灰度图等图片的转换，传入待转换的图片对象，传入转换策略，如彩色图转灰度图的`cv2.COLOR_BGR2GRAY`属性，即可返回一张目标图。

如：

` cv2.imshow('cxk', cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))`

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902193031805.png" width="200px">

5.img对象的其它常用属性 - 属于numpy的知识，对于numpy的ndarray对象都适用。

①shape属性

​	对于彩色如，打印出来是一个三元组，第一个维度的值是图片的高度h，第二个是宽度w，第三个是通道数c。

```python
img.shape
# 结果 (339, 421, 3)
```

②size属性

​	img对象本质上是numpy包下的ndarray对象，本质上是一个多维的矩阵，size属性可以查看矩阵的元素个数。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902185015251.png" width="200px">

③dtype属性 - 即数据元素的类型

​	图片中为uint8。每一个像素对应的单通道的值为0-255的一个uint8的数。

6.img的copy方法 - 复制一份矩阵

`img_c = img.copy()`

## 视频的打开、关闭、和常用方法

​	前沿：视频的本质是图片的时间序列，所以对图片能处理，就能处理视频，处理视频的本质是处理图片，我们对摄像头-视频的处理，本质上还要归结于对单张图片-一帧视频的处理上。所以读取视频本质上是逐帧处理图片，单个图片的逻辑我们写好，写一个while循环就能处理视频了。

1.打开视频

```python
# 打开视频
vc = cv2.VideoCapture('cxk.mp4')
```

​	用VideoCapture方法打开一个视频，传入视频的路径，获得视频的迭代器对象。

2.逐帧读取视频的每一帧并直到播放完毕或按下ESC键退出视频播放

```python
while vc.isOpened():  # 确保视频打开成功再进入循环处理每一帧
    is_open, frame = vc.read()  # vc.read()方法读取当前帧（vc内置了一个指针，类似于C读取文件的时候的指针）
    if is_open == False:
        break
    cv2.imshow('cxk', frame)
    if (cv2.waitKey(10) & 0xFF) == 27:
        break
```

​	对于同一个vc对象，内置的指针是一次性的，即每一次调用read方法，就会读取当前指针指向的视频帧，返回一个读取状态和返回帧，我们可以拿到这个返回帧frame并对其进行处理，然后指针往下挪动一个帧。

​	然后我们进行出口处理，如果没打开成功，证明视频读完了，可以br。否则就可以处理每一帧了，比如你可以先imshow一下， 然后这部分的代码的意思是如果按下了Esc键，就可以退出循环了。

①waitKey函数其实是等待x秒，暂停程序，并监听键盘的输入，如果检测到键盘输入，则会返回键盘输入键对应值的ASCII码，ESC的ASCII为27，而0xFF是掩码，和掩码and意思是取后8位，忽略前面24位没用的信息。如果用户在某一帧播放时按下了Esc，这一轮循环就会返回27，掩码之后和27比较就会相等，就会退出循环，即暂停播放。

​	如果没有按下，则返回-1.这也不难理解如果传入0会发生什么，如果传入0，则相当于无限等待，程序会一直在这里阻塞，直到用户按下任意键。

​	当然，传入的x越大，单frame处等待的时间越长，视频显得倍速越慢，帧率越低，越卡顿。

3.关闭视频并关闭所有窗口（搭配使用）

​	资源在使用完之后，必须释放-如会释放摄像头等资源，如果不释放资源，则会造成资源分配问题。这是标准的收尾的代码。

```python
vc.release()  # release vc对象
cv2.destroyAllWindows() # 关闭opencv打开的所有窗口
```

## 图片的ROI（切片）

​	ROI操作指的是：Region Of Interesting. 你感兴趣的区域，其实就是图片切片。

​	我们上面提到，图片本质是ndarray，所以可以对高维矩阵进行切片。和Python中对列表的切片类似，ndarray是高维矩阵，以彩色图为例，彩色图是三维的矩阵，有h，w，c三个维度，所以切片也对应有三个维度，需要每个维度单独处理。

①三个维度独立切片

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902193612942.png" width="400px">

​	以上面这个三维矩阵为例，每一个维度的切片都和python中list的切片是一样的，都是半开区间，即[from, to)。

​	当然，你可以选择忽略后面的部分，只对h和w维度进行切片，如下：

`show_img('region-test', img[100:300, 0:200])`

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902194043904.png" width="200px">

​	总之，你就把图片当成三维矩阵就好了，对矩阵的切片就是ROI。

②彩色图的通道提取和合并

①通道分离

​	如果我想获得彩色图的某一个通道的矩阵信息，如我只想获得红色部分的信息。

​	可以调用**cv2.split**方法，传入img对象，获得b,g,r三个维度的矩阵信息。都是二维的。

`b,g,r = cv2.split(img)`

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902194453495.png" width="400px">

②通道合并

​	将同维度的低维矩阵合并，可以构造多通道的图片 - `img_merge = cv2.merge((b,g,r))`

// 两个单通道的也可以合并，但是不能imshow，这一点要注意。

③ndarray中，实现**区域赋值**，比如我想把三通道图片的某两个通道都置为0.只显示一个通道的信息。 

```python
img_c = img.copy()  # img对象实现矩阵的copy
img_c[:,:,0] = 0
img_c[:,:,1] = 0
# 只保留r通道
show_img('r', img_c)
```

结果：

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902194943196.png" width="200px">

​	注意，这**不是切片**，而是**<u>ndarray数组的区域访问 & 赋值。</u>** 前面两个维度选择切片范围，第三维度用来访问制定通道。

## 边界填充

​	本节我们学习给图片加边界的方法，以及几种填充策略。

​	边界填充指的是将传入的img图片的上下左右分别加上传入参数大小的数量，然后构成一张新的图片，很显然刚刚多出来的部分需要用一种策略填充，这里介绍四种填充策略。

​	方法：`cv2.copyMakeBorder`,传入的参数依次是原img对象，上下左右四个像素值大小，填充策略参数-显式指定borderType，如果是常数填充法，还需要指定颜色值value。

①常数填充法

// 这里也注意，cv2的属性都是x_y，x是和这个属性相关的分类，比如边框有关的就是BORDER开头。

```python
show_img('make-border', cv2.copyMakeBorder(img_merge, 50,50,50,50,borderType=cv2.BORDER_CONSTANT,value=0))
```

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902200327308.png" width="200px">

②复制法

​	borderType是**cv2.BORDER_REPLICATE**, 即复制，也就是说**用边缘的最后一行/列像素进行填充**。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902201025118.png" width="200px">

③反射法

​	传入的borderType值是cv2.BORDER_REFLECT,也可也是cv2.BORDER_REFLECT_101,没有太大区别-只有细微的区别。即**以边界为镜面进行对称**，然后截取框选需要的部分。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902201128368.png" width="200px">

④包裹法

​	你可以理解为将图片无限复制包裹住这张图片，然后以它为中心进行直接截取。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902201504187.png" width="200px">

## 数值计算

1.numpy中的矩阵 + 整数

​	以dtype为uint8的彩色图为例，img + 10会导致每一个元素都 + 10，超出255会发生溢出截断，即从效果上相当于对256取模了。

```python
img[50:65, 60:65] + 50
```

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902202929711.png" width="400px">

​	这是加50之前和之后的矩阵对比图，可以发现溢出在硬件层面numpy选择了截断。

2.numpy中的矩阵 + 矩阵

​	类似的，两个同维度的矩阵是可以相加或进行其他多种运算的，对应位置的元素进行相加，如果溢出了，也是采用截断的方式，比如img和自己相加。

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902203154229.png" width="200px">

3.**cv2中的add方法** - 不截断（如果达到了所能表示最大值255，那就取255）

```python
img1 = img[50:65, 60:65]
img2 = img[50:65, 60:65]
cv2.add(img1, img2)
```

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902203439047.png" width="200px">

4.图片缩放 **resize方法** 

①指定新宽度和高度

`cv2.resize(img, (new_w, new_h))`

​	注意，传入的元组是(w,h), 即**第一个是宽度，第二个是高度**。不要搞错。而且**<u>是缩放操作</u>**，不是常数填充的。而且是需要一个对象去接收的，返回resize之后新图片。

```python
img2 = cv2.resize(img2, (421,339))
```

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902210022515.png" width="200px">

②指定放大比例

​	传入的元组-第二个参数为(0,0)，然后显式指定fx和fy，即x水平方向变为原来的倍数，y垂直方向变为原来的倍数，比如x放大为3倍，y放大为2倍（也可也是(0,1)的倍数-即缩小）

```python
img2 = cv2.resize(img2, (0, 0), fx=3, fy=2)
```

​	结果太大了，不显示了。

5.图片的融合 **addWeighted方法**

​	传入五个参数，分别是img_merged = img1 * α + img2 * β + b, 按照这五个参数传即可。本质上还是numpy的运算。相当于加权平均得到新的图片，新图片会有原来两个图片的影子。

​	前提是img1和img2的同样规格的图片，如果不一样需要先对其中一个resize。

结果：α = 0.5， β = 0.5

<img src="%E7%AC%94%E8%AE%B0.assets/image-20250902210238824.png" width="200px">

// 2025年9月2日21:07:52 finished	
